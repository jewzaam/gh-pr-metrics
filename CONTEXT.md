# GitHub Pull Request Metrics Tool - LLM Context

Generated By: Cursor (Claude Sonnet 4.5)

## Project Overview

This project implements a command-line tool that generates CSV reports containing key metrics for all pull requests in a GitHub repository within a specified time range. The tool is designed to help teams analyze their pull request workflow and identify bottlenecks or trends.

## Key Features

1. **Automated PR Metrics Collection**: Fetches comprehensive data about pull requests including creation time, review readiness, comments, reviews, and current status
2. **Flexible Time Range**: Analyze PRs from any time period (default: last 365 days)
3. **CSV Output**: RFC 4180 compliant, UTF-8 encoded, Excel-compatible CSV format
4. **Smart Defaults**: Works with minimal configuration by detecting repository information from local git config
5. **Bot Comment Detection**: Separately tracks bot comments vs. human comments
6. **Unique Reviewer Tracking**: Counts unique reviewers who requested changes

## Architecture Overview

### Component Structure
```
gh-pr-metrics/
├── src/                      # Source code directory
│   └── gh_pr_metrics.py     # Main application (single file implementation)
├── tests/                    # Test suite
│   ├── unit/                 # Unit tests (100% mocked)
│   │   ├── test_argument_parsing.py
│   │   ├── test_csv_output.py
│   │   ├── test_date_handling.py
│   │   ├── test_github_api.py
│   │   ├── test_main.py
│   │   ├── test_pr_processing.py
│   │   └── test_repo_detection.py
│   └── integration/          # Integration tests (placeholder for future)
├── docs/                     # Documentation
│   ├── requirements.md       # Detailed functional/non-functional requirements
│   └── unit-test-plan.md     # Comprehensive testing strategy
├── make/                     # Modular Makefile structure
│   ├── common.mk            # Common variables and constants
│   ├── env.mk               # Environment setup targets
│   ├── lint.mk              # Linting and formatting
│   └── test.mk              # Testing and coverage
├── .github/workflows/        # GitHub Actions CI/CD
│   ├── test.yml             # Run tests on Python 3.10, 3.11, 3.12
│   ├── lint.yml             # Run linting
│   ├── format.yml           # Check code formatting
│   └── coverage.yml         # Generate coverage reports
├── Makefile                 # Main Makefile (includes modular makefiles)
└── pyproject.toml           # Modern Python project configuration (PEP 517/518)
```

### Implementation Details

**Single File Design**: The entire application is implemented in `src/gh_pr_metrics.py` (498 lines) for simplicity and ease of deployment. This decision was made to prioritize quick deployment over architectural complexity.

**Version**: 0.1.0 (semantic versioning)

**Python Support**: Python 3.10, 3.11, 3.12

**Test Coverage**: 71% (threshold: 70%, 43 unit tests passing)

### Data Flow
1. **Input**: User provides repository info and time range via CLI
2. **Repository Detection**: Auto-detects from `git config` if not specified
3. **API Interaction**: Tool queries GitHub REST API v3 for PR data with pagination
4. **Processing**: Calculates metrics (ready time, comment counts, review states)
5. **Output**: Generates CSV with all metrics (stdout or file)

## Key Technical Decisions

### API Choice
- Uses GitHub REST API v3 (stable, well-documented, no GraphQL complexity)
- Supports both authenticated and unauthenticated requests
- Handles pagination automatically for large result sets
- GitHub.com only (GitHub Enterprise not supported)

### Authentication Strategy
- Environment variable (`GITHUB_TOKEN`) for simplicity
- Falls back to unauthenticated for public repos
- Clear error messages for auth failures
- Future consideration: GitHub CLI (`gh`) authentication integration

### Date Handling
- All timestamps in ISO 8601 format for consistency
- Supports ISO 8601, RFC 3339, and Unix timestamps
- Uses `python-dateutil` for flexible parsing
- Default time range: today minus 365 days

### Error Handling Philosophy
- Fail gracefully with informative messages
- Continue processing other PRs if one fails (partial data mode)
- Adds `errors` column to CSV if issues occurred
- Log errors with `--debug` flag for troubleshooting
- No retry logic in v0.1.0 (future enhancement)

### Build System
- **Modular Makefiles**: Separated into `make/common.mk`, `make/env.mk`, `make/lint.mk`, `make/test.mk`
- **Virtual Environment**: Uses `.venv` with `uv` package manager for faster installs
- **Color-coded Output**: Green ✅ for success, red ❌ for failures
- **CI/CD**: GitHub Actions workflows for test, lint, format, coverage
- **Coverage Threshold**: 70% enforced in CI

## Implementation Guidelines

### Code Style
- Follow PEP 8 Python style guide
- Black formatter with 100-character line length
- Flake8 linting with E203, W503 ignored
- Type hints for better code clarity (mypy optional)
- Descriptive variable and function names

### Testing Approach
- Mock all external dependencies (GitHub API, file system, subprocess)
- Use `pytest` with `requests-mock` for API mocking
- Test edge cases and error conditions
- 43 unit tests covering 71% of code
- Integration tests placeholder (future: real API calls with `RUN_INTEGRATION_TESTS=1`)
- **Prefer updating existing tests** over creating new tests when adding functionality, as long as updates don't violate the test's scope/boundaries

### Performance Considerations
- Minimize API calls through efficient pagination
- Process data iteratively to manage memory
- Progress indicators: "Processing PR 45/150..." style
- Respects GitHub API pagination (no explicit rate limiting in v0.1.0)

## CSV Output Format

### Columns
1. `pr_number`: Pull request number (integer)
2. `created_at`: ISO 8601 timestamp when PR was created
3. `ready_for_review_at`: ISO 8601 timestamp when PR became ready (or created_at if never draft)
4. `comments_total`: Total number of comments (integer)
5. `non_ai_bot_comment_count`: Number of non-AI bot comments (integer, excludes AI bots)
6. `ai_bot_comment_count`: Number of AI bot comments (integer)
7. `non_ai_bot_login_names`: Comma-separated list of non-AI bot logins that commented
8. `ai_bot_login_names`: Comma-separated list of AI bot logins that commented
9. `change_requests_total`: Total number of "changes requested" reviews (integer)
10. `change_requests_unique`: Number of unique reviewers who requested changes (integer)
11. `approvals`: Number of approvals (integer, latest state per reviewer)
12. `status`: One of: `draft`, `open`, `closed`, `merged`
13. `errors`: Optional column, only present if errors occurred during processing

### Format Details
- RFC 4180 compliant CSV
- UTF-8 encoding with BOM for Excel compatibility
- Proper escaping of special characters (commas, quotes, newlines)
- Empty string for missing values (not "N/A" or null)

## Common Patterns and Solutions

### Calculating "Ready for Review" Time
```python
# PRs that were never drafts use creation time
if not pr.get("draft", False):
    # Check timeline events for ready_for_review
    events_url = pr["_links"]["timeline"]["href"]
    events = fetch_timeline_events(events_url)
    ready_events = [e for e in events if e.get("event") == "ready_for_review"]
    
    if ready_events:
        return ready_events[-1]["created_at"]  # Use latest
    else:
        return pr["created_at"]  # Never was draft
else:
    # Currently draft, return None or handle appropriately
    return None
```

### Counting Reviews by State (Latest Per Reviewer)
```python
# Get the most recent review state from each reviewer
reviews_by_user = {}
for review in reviews:
    user = review["user"]["login"]
    submitted_at = review["submitted_at"]
    
    if user not in reviews_by_user or submitted_at > reviews_by_user[user]["submitted_at"]:
        reviews_by_user[user] = review

# Count approvals (APPROVED state)
approvals = sum(1 for r in reviews_by_user.values() if r["state"] == "APPROVED")

# Count change requests (CHANGES_REQUESTED state)
change_requests_by_user = [
    r["user"]["login"] for r in reviews_by_user.values() 
    if r["state"] == "CHANGES_REQUESTED"
]
change_requests_total = len(change_requests_by_user)
change_requests_unique = len(set(change_requests_by_user))
```

### Counting Comments (Non-AI Bot vs. AI Bot)
```python
# AI bots hardcoded list (based on analysis)
AI_BOTS = ["cursor[bot]"]

def count_comments(pr_number, owner, repo, token):
    # Fetch both review comments and issue comments
    review_comments = fetch_review_comments(owner, repo, pr_number, token)
    issue_comments = fetch_issue_comments(owner, repo, pr_number, token)
    
    all_comments = review_comments + issue_comments
    
    total = len(all_comments)
    
    # Collect bot logins and counts (separate AI from non-AI)
    non_ai_bot_logins = set()
    ai_bot_logins = set()
    non_ai_bot_count = 0
    ai_bot_count = 0
    
    for c in all_comments:
        if c.get("user", {}).get("type") == "Bot":
            login = c["user"]["login"]
            
            if re.match(ai_bot_pattern, login):
                ai_bot_logins.add(login)
                ai_bot_count += 1
            else:
                non_ai_bot_logins.add(login)
                non_ai_bot_count += 1
    
    # Convert to comma-separated strings, sorted for consistency
    non_ai_bot_names = ",".join(sorted(non_ai_bot_logins))
    ai_bot_names = ",".join(sorted(ai_bot_logins))
    
    return total, non_ai_bot_count, ai_bot_count, non_ai_bot_names, ai_bot_names
```

### Repository Detection from Git Config
```python
import subprocess
import re

def get_repo_from_git():
    try:
        # Get remote URL
        result = subprocess.run(
            ["git", "config", "--get", "remote.origin.url"],
            capture_output=True, text=True, check=True
        )
        url = result.stdout.strip()
        
        # Parse SSH: git@github.com:owner/repo.git
        # Parse HTTPS: https://github.com/owner/repo.git
        match = re.search(r'[:/]([^/]+)/([^/]+?)(\.git)?$', url)
        if match:
            return match.group(1), match.group(2).replace('.git', '')
    except subprocess.CalledProcessError:
        pass
    
    return None, None
```

## External Dependencies

All dependencies are defined in `pyproject.toml` using modern Python packaging standards (PEP 517/518).

### Required Python Packages (`[project.dependencies]`)
- `requests>=2.28.0`: HTTP client for GitHub API
- `python-dateutil>=2.8.0`: Flexible date parsing
- `argcomplete>=2.0.0`: Bash completion for CLI

### Development Dependencies (`[project.optional-dependencies.dev]`)
- `pytest>=7.0.0`: Testing framework
- `pytest-cov>=4.0.0`: Coverage reporting
- `pytest-mock>=3.10.0`: Mocking utilities
- `requests-mock>=1.9.3`: Mock HTTP responses
- `coverage>=7.0.0`: Coverage measurement
- `black>=23.0.0`: Code formatting
- `flake8>=6.0.0`: Linting
- `mypy>=1.0.0`: Type checking (optional)
- `types-requests>=2.28.0`: Type stubs for requests
- `types-python-dateutil>=2.8.0`: Type stubs for dateutil

Install with: `pip install -e ".[dev]"`

## GitHub API Endpoints Used

1. **List Pull Requests**: `GET /repos/{owner}/{repo}/pulls`
   - Parameters: `state=all`, `sort=created`, `direction=desc`, `per_page=100`
   - Returns: Basic PR information with pagination

2. **Get Pull Request**: `GET /repos/{owner}/{repo}/pulls/{number}`
   - Returns: Detailed PR information including draft status

3. **List Timeline Events**: `GET /repos/{owner}/{repo}/issues/{number}/timeline`
   - Returns: Timeline events (including `ready_for_review`)
   - Requires: `Accept: application/vnd.github.mockingbird-preview`

4. **List PR Reviews**: `GET /repos/{owner}/{repo}/pulls/{number}/reviews`
   - Returns: Review states and reviewers

5. **List Review Comments**: `GET /repos/{owner}/{repo}/pulls/{number}/comments`
   - Returns: Inline code review comments

6. **List Issue Comments**: `GET /repos/{owner}/{repo}/issues/{number}/comments`
   - Returns: General PR conversation comments

## Common Challenges and Solutions

### Challenge: API Rate Limits
**Current Solution**: 
- No automatic retry or rate limit handling in v0.1.0
- Clear error messages when rate limit exceeded
- Suggestion to use `GITHUB_TOKEN` for higher limits

**Future Enhancement**:
- Check `X-RateLimit-Remaining` header
- Implement exponential backoff for 403 responses
- Cache results when possible

### Challenge: Large Repositories
**Solution**:
- Use pagination efficiently (100 items per page)
- Filter PRs by date range early
- Show progress indicators: "Processing PR 45/150..."
- Process PRs one at a time, not all in memory

### Challenge: Data Consistency
**Solution**:
- Fetch all data for a PR in sequence
- Use the most recent review state per reviewer
- Handle missing or null values gracefully (empty string in CSV)
- Continue with partial data if errors occur (add to `errors` column)

### Challenge: Bot Comment Detection
**Solution**:
- Check for `[bot]` suffix in username (GitHub convention)
- Examples: `dependabot[bot]`, `github-actions[bot]`, `cursor[bot]`
- Separate metric for bot vs. human comments
- GitHub API also provides `type: "Bot"` for reliable detection

**Bot Categories**:
- **AI Review Bots**: `cursor[bot]` - Generates structured code reviews with bug analysis
- **Simple Automation**: `github-actions[bot]`, `openshift-ci[bot]`, `sonarqubecloud[bot]` - CI/CD status, test results

**API Detection**:
```python
# Current implementation uses type field (correct approach)
if comment.get("user", {}).get("type") == "Bot":
    bot_comments += 1

# Alternative: Username suffix (less reliable, depends on naming convention)
is_bot = "[bot]" in user["login"]

# Get bot details via API
# gh api /users/{bot-name}%5Bbot%5D
# Returns: {login, type: "Bot", html_url: "https://github.com/apps/{app-name}"}
```

**Implementation**: Separated AI review bots from simple automation bots. AI bots identified via configurable regex pattern (default: `cursor\[bot\]`) and tracked separately with dedicated columns for count and names. Pattern customizable via `--ai-bot-regex` CLI argument. Setting pattern to empty string or None disables AI bot detection (all bots treated as non-AI).

### Challenge: Time Zone Issues
**Solution**:
- GitHub API returns UTC timestamps in ISO 8601 format
- Use `python-dateutil` for parsing (handles timezones)
- Accept timezone-aware inputs from users
- Output in original ISO 8601 format (preserves timezone)

## Development Workflow

### Setup
```bash
# Install the tool with runtime dependencies
make install

# Or install development dependencies (includes runtime deps + testing/linting tools)
make requirements-dev
```

### Development Commands
```bash
make help              # Show all available targets
make format            # Format code with black
make lint              # Run flake8 linting
make test              # Run all unit tests
make test-unit         # Run unit tests only
make test-integration  # Run integration tests (future)
make coverage          # Run tests with coverage report and enforce 70% threshold
make coverage-report   # Generate coverage report (no threshold)
make clean             # Remove temporary files and .venv
```

### CI/CD Pipeline
- **Pull Request**: Runs test, lint, format check, coverage on all PRs
- **Push to Main**: Runs same checks on push to main branch
- **Coverage Comments**: Posts PR comment with coverage badge and status
- **Matrix Testing**: Tests on Python 3.10, 3.11, 3.12

## Usage Examples

### Basic Usage
```bash
# Analyze PRs from current repository (last 365 days)
.venv/bin/gh-pr-metrics

# Specify repository explicitly
.venv/bin/gh-pr-metrics --owner microsoft --repo vscode

# Custom time range
.venv/bin/gh-pr-metrics --start 2024-01-01 --end 2024-12-31

# Output to file
.venv/bin/gh-pr-metrics --output metrics.csv
```

### With Authentication
```bash
# Set token for private repos or higher rate limits
export GITHUB_TOKEN=ghp_xxxxxxxxxxxxx
.venv/bin/gh-pr-metrics --owner myorg --repo private-repo
```

### Debug Mode
```bash
# Enable debug logging
.venv/bin/gh-pr-metrics --debug

# Debug with specific repo
.venv/bin/gh-pr-metrics --owner kubernetes --repo kubernetes --debug
```

## Debugging and Troubleshooting

### Common Issues

1. **"Repository not found" or "Could not detect repository"**
   - Ensure you're in a git repository with `git remote -v`
   - Provide explicit `--owner` and `--repo` arguments
   - Check repository exists and is accessible
   - Verify authentication for private repos

2. **"API rate limit exceeded"**
   - Add `GITHUB_TOKEN` environment variable for higher limits (5000/hour vs 60/hour)
   - Wait for rate limit reset (check error message for time)
   - Reduce time range to fetch less data
   - Use `--start` and `--end` to limit scope

3. **"Invalid date format"**
   - Use ISO 8601: `2024-01-01` or `2024-01-01T00:00:00Z`
   - Check start is before end date
   - Verify timezone if specified (e.g., `2024-01-01T00:00:00-08:00`)

4. **Missing metrics in CSV**
   - Check `errors` column for specific PR failures
   - Enable `--debug` to see detailed error messages
   - Some PRs may have partial data (expected behavior)

### Debug Mode Output
```bash
$ .venv/bin/gh-pr-metrics --debug
DEBUG:root:Detected repository: owner=myorg, repo=myrepo
DEBUG:root:Date range: 2023-10-28T00:00:00Z to 2024-10-28T23:59:59Z
DEBUG:root:Fetching pull requests...
DEBUG:root:Processing PR #123...
DEBUG:root:Fetching reviews for PR #123...
```

## Future Enhancements (Not in Current Scope)

### Near-term (v0.2.0)
1. **GitHub CLI Authentication**: Integration with `gh auth` for token management
2. **Retry Logic**: Exponential backoff for transient failures
3. **Rate Limit Management**: Automatic detection and waiting
4. **Integration Tests**: Real API calls with environment flag

### Medium-term (v0.3.0)
5. **GitLab Support**: Extend to GitLab APIs
6. **Caching**: Store results for repeated queries
7. **Additional Metrics**: Time to merge, review turnaround, files changed
8. **Filtering**: By labels, authors, reviewers, or file patterns

### Long-term (v1.0.0)
9. **Multiple Repos**: Analyze organization-wide metrics
10. **GraphQL Support**: More efficient data fetching
11. **Export Formats**: JSON, Excel, Parquet
12. **Visualizations**: Generate charts from data
13. **Incremental Updates**: Only fetch new PRs since last run
14. **Real-time Mode**: Watch for new PRs via webhooks

## Related Tools and Inspiration

- **gh-pulls-summary**: Similar tool focused on open PR summaries
- **prreview**: PR review tool with worktree management
- **GitHub CLI (gh)**: Official GitHub command-line tool
- **GitHub Insights**: GitHub's built-in analytics (limited, no CSV export)

## Contributing Guidelines

When working on this codebase:

1. **Read the requirements** (`docs/requirements.md`) first
2. **Follow the test plan** (`docs/unit-test-plan.md`)
3. **Maintain backwards compatibility** for CLI arguments
4. **Add tests for new features** before implementing (71% coverage minimum)
5. **Prefer updating existing tests** over creating new tests when the update fits within the test's scope
6. **Update documentation** for any changes (requirements, CONTEXT.md)
7. **Run quality checks**: `make format lint test coverage`
8. **Use meaningful commit messages** with `Assisted-by: Cursor (Claude Sonnet 4.5)`
9. **Add "Generated By" header** to new files

## Security Considerations

- Never commit tokens or credentials (use environment variables)
- Validate all user inputs (dates, repository names)
- Sanitize data for CSV injection (handled by `csv` module)
- Use HTTPS for all API calls (enforced by `requests`)
- Be cautious with subprocess calls (only `git config`)
- Follow GitHub's security best practices
- Review dependencies for known vulnerabilities

## Project Structure Rationale

### Why Single File in src/?
- **Simplicity**: Easier to understand and deploy
- **Quick Start**: Minimal setup for new contributors
- **Self-contained**: No complex imports or package structure
- **Standard Structure**: Follows Python packaging conventions (src/ layout)
- **Future**: May split into modules if exceeds ~1000 lines

### Why Modular Makefiles?
- **Maintainability**: Separate concerns (env, test, lint)
- **Reusability**: Common patterns across projects
- **Consistency**: Follows organizational template (`template-python`)
- **Extensibility**: Easy to add new targets without cluttering main Makefile

### Why Both Unit and Integration Tests?
- **Unit Tests**: Fast, isolated, 100% mocked (runs in CI)
- **Integration Tests**: Slow, real API, validates end-to-end (manual)
- **Separation**: Allows quick feedback loop during development

## Key Files to Review First

When starting work on this project, read these files in order:

1. **`docs/requirements.md`**: Understand what the tool should do
2. **`CONTEXT.md`**: This file - understand how it works
3. **`pyproject.toml`**: Project configuration, dependencies, tool settings
4. **`src/gh_pr_metrics.py`**: Main implementation (498 lines)
5. **`Makefile`** and **`make/*.mk`**: Build and test system
6. **`tests/`**: Test coverage and patterns

## Metrics Definitions

### Comment Counts
- **Total Comments**: All comments from both `/pulls/{number}/comments` (review comments) and `/issues/{number}/comments` (issue comments)
- **Bot Comments**: Comments where username contains `[bot]` suffix

### Change Request Counts
- **Total Change Requests**: All "CHANGES_REQUESTED" reviews (may include multiple from same reviewer)
- **Unique Change Requesters**: Count of distinct reviewers who requested changes

### Approval Count
- **Approvals**: Count of reviewers whose latest review state is "APPROVED"
- **Latest State Only**: If a reviewer approves then requests changes, only the change request counts

### Status Values
- **draft**: PR is currently in draft state
- **merged**: PR was merged (closed with merge)
- **closed**: PR was closed without merging
- **open**: PR is open and ready for review (not draft)

### Ready for Review Time
- **Never Draft**: PRs created as ready use `created_at`
- **Converted from Draft**: Uses timestamp of latest `ready_for_review` event
- **Still Draft**: May be null or use `created_at` (implementation detail)
