#!/usr/bin/env python3
# Generated By: Cursor (Claude Sonnet 4.5)
"""
CSV Command Module

Generates CSV metrics from cached JSON data.
"""

import argparse
from pathlib import Path
from typing import Optional

from .base_command import BaseCommand
from data import MetricsGenerator


class CsvCommand(BaseCommand):
    """
    Generate CSV metrics from cached JSON data.

    Pure local processing - no GitHub API calls.
    Reads PR JSON from cache and calculates metrics.
    """

    def needs_github_client(self) -> bool:
        """CSV command does not need GitHub client."""
        return False

    def add_arguments(self, parser: argparse.ArgumentParser) -> None:
        """Add csv-specific arguments."""
        parser.add_argument(
            "--owner",
            help="Repository owner",
        )
        parser.add_argument(
            "--repo",
            help="Repository name",
        )
        parser.add_argument(
            "--output",
            help="CSV output file path",
        )
        parser.add_argument(
            "--all",
            action="store_true",
            help="Generate CSV for all repositories with cached JSON",
        )

    def run(self, args: argparse.Namespace) -> int:
        """
        Execute csv command.

        Returns:
            Exit code (0 for success, non-zero for failure)
        """
        if args.all:
            return self._run_csv_all(args)
        else:
            if not args.owner or not args.repo:
                self.logger.error("CSV generation requires --owner and --repo (or use --all)")
                return 1
            return self._run_csv_single(args)

    def _run_csv_single(self, args: argparse.Namespace) -> int:
        """Generate CSV for a single repository."""
        owner = args.owner
        repo = args.repo
        output_arg = args.output

        # Determine output path
        output_file = self._resolve_output_path(owner, repo, output_arg)
        if not output_file:
            self.logger.error(
                "No output file specified. Provide --output, or ensure csv_file is set in state, "
                "or configure output_pattern in config file"
            )
            return 1

        # Generate CSV
        result = self._generate_csv_for_repo(owner, repo, output_file)

        # Update state if --output was explicitly provided
        if output_arg:
            # Note: We don't update timestamp, only csv_file
            repo_state = self.state_manager.get_repo_state(owner, repo)
            if repo_state:
                # Preserve existing timestamp
                self.state_manager.update_repo(owner, repo, repo_state["timestamp"], output_file)

        return result

    def _run_csv_all(self, args: argparse.Namespace) -> int:
        """Generate CSV for all repositories with cached JSON."""
        # Get all tracked repos
        repos = self.state_manager.get_all_tracked_repos()
        if not repos:
            self.logger.info("No tracked repositories found")
            return 0

        self.logger.info("Generating CSV for %d repositories", len(repos))

        failed_repos = []
        for repo_info in repos:
            owner = repo_info["owner"]
            repo = repo_info["repo"]
            csv_file = repo_info.get("csv_file")

            if not csv_file:
                self.logger.warning("Skipping %s/%s: no csv_file in state", owner, repo)
                continue

            self.logger.info("Generating CSV for %s/%s â†’ %s", owner, repo, csv_file)
            result = self._generate_csv_for_repo(owner, repo, csv_file)

            if result != 0:
                failed_repos.append(f"{owner}/{repo}")

        if failed_repos:
            self.logger.error("Failed repositories: %s", ", ".join(failed_repos))
            return 1

        self.logger.info("Successfully generated CSV for all repositories")
        return 0

    def _resolve_output_path(
        self, owner: str, repo: str, output_arg: Optional[str]
    ) -> Optional[str]:
        """
        Resolve output file path.

        Priority:
        1. CLI --output argument
        2. State file csv_file value
        3. Config output_pattern
        """
        if output_arg:
            return output_arg

        # Check state file
        repo_state = self.state_manager.get_repo_state(owner, repo)
        if repo_state and repo_state.get("csv_file"):
            return repo_state["csv_file"]

        # Check config pattern
        if self.config.output_pattern:
            from gh_pr_metrics import expand_output_pattern

            return expand_output_pattern(self.config.output_pattern, owner, repo)

        return None

    def _generate_csv_for_repo(self, owner: str, repo: str, output_file: str) -> int:
        """
        Generate CSV for a repository from cached JSON.

        Args:
            owner: Repository owner
            repo: Repository name
            output_file: Output CSV file path

        Returns:
            Exit code (0 for success, non-zero for failure)
        """
        # Find all JSON files for this repo
        json_dir = Path(self.config.raw_data_dir) / "github.com" / owner / repo

        if not json_dir.exists():
            self.logger.warning("No cached JSON found for %s/%s at %s", owner, repo, json_dir)
            return 0

        json_files = list(json_dir.glob("*.json"))
        if not json_files:
            self.logger.warning("No JSON files found in %s", json_dir)
            return 0

        self.logger.info("Found %d JSON files for %s/%s", len(json_files), owner, repo)

        # Create metrics generator
        metrics_gen = MetricsGenerator(self.config, self.logger)

        # Process all PRs
        all_metrics = []
        for json_file in sorted(json_files):
            try:
                pr_number = int(json_file.stem)

                # Read JSON
                pr_json_data = metrics_gen.read_pr_json(owner, repo, pr_number)
                if not pr_json_data:
                    continue

                # Create minimal PR object for metrics calculation
                pr = {
                    "number": pr_number,
                    "title": pr_json_data.get("title", ""),
                    "user": {"login": pr_json_data.get("author", "")},
                    "created_at": pr_json_data.get("created_at", ""),
                    "html_url": pr_json_data.get("url", ""),
                    "state": pr_json_data.get("state", "open"),
                    "merged_at": pr_json_data.get("merged_at"),
                    "closed_at": pr_json_data.get("closed_at"),
                    "draft": pr_json_data.get("draft", False),
                    "additions": pr_json_data.get("additions", 0),
                    "deletions": pr_json_data.get("deletions", 0),
                    "changed_files": pr_json_data.get("changed_files", 0),
                }

                # Calculate metrics (without token or github_client for CSV regeneration)
                metrics = metrics_gen.calculate_metrics(pr, pr_json_data, owner, repo, None, None)
                all_metrics.append(metrics)

            except Exception as e:
                self.logger.warning("Failed to process %s: %s", json_file, e)
                continue

        if not all_metrics:
            self.logger.warning("No metrics generated for %s/%s", owner, repo)
            return 0

        # Write CSV
        try:
            # Ensure output directory exists
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            # Write CSV (no merge mode - always complete regeneration)
            self.csv_manager.write_csv(all_metrics, output_file, merge_mode=False)

            self.logger.info("Generated CSV with %d PRs: %s", len(all_metrics), output_file)
            return 0

        except Exception as e:
            self.logger.error("Failed to write CSV to %s: %s", output_file, e)
            return 1
