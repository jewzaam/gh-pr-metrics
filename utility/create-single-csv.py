#!/usr/bin/env python3
# Generated By: Cursor (Claude Sonnet 4.5)
"""
Merge all CSV files in a directory into a single CSV file.
Extracts owner and repo from filename pattern: {owner}_{repo}.csv
Also creates a rollup CSV with aggregated metrics by owner+repo.
"""

import csv
import sys
import os
from pathlib import Path
from collections import defaultdict


def safe_float(value):
    """Convert value to float, return 0.0 if conversion fails or value is empty."""
    if value is None or value == "":
        return 0.0
    try:
        return float(value)
    except (ValueError, TypeError):
        return 0.0


def create_rollup(rollup_data):
    """Create rollup CSV with aggregated metrics by owner+repo."""
    rollup_file = "all-data-rollup.csv"

    rollup_header = [
        "owner",
        "repo",
        "total_pr_count",
        "merged_pr_count",
        "closed_pr_count",
        "open_pr_count",
        "draft_pr_count",
        "pr_count_with_ai_bots",
        "pr_count_without_ai_bots",
        "avg_days_open_all",
        "avg_days_open_merged",
        "avg_days_open_closed",
        "avg_days_open_with_ai_bots",
        "avg_days_open_without_ai_bots",
        "avg_days_in_review_all",
        "avg_days_in_review_merged",
        "avg_days_in_review_with_ai_bots",
        "avg_days_in_review_without_ai_bots",
        "total_comments",
        "total_non_ai_bot_comments",
        "total_ai_bot_comments",
        "total_changes_requested",
        "total_approvals",
        "avg_comments_per_pr",
        "avg_non_ai_bot_comments_per_pr",
        "total_lines_added",
        "total_lines_deleted",
        "total_files_changed",
        "total_line_changes",
        "avg_lines_added_per_pr",
        "avg_files_changed_per_pr",
    ]

    with open(rollup_file, "w", newline="", encoding="utf-8") as outfile:
        writer = csv.DictWriter(outfile, fieldnames=rollup_header)
        writer.writeheader()

        for (owner, repo), data in sorted(rollup_data.items()):
            total = data["total_pr_count"]
            merged = data["merged_pr_count"]
            closed = data["closed_pr_count"]
            with_ai_bots = data["pr_count_with_ai_bots"]
            without_ai_bots = data["pr_count_without_ai_bots"]

            row = {
                "owner": owner,
                "repo": repo,
                "total_pr_count": total,
                "merged_pr_count": merged,
                "closed_pr_count": closed,
                "open_pr_count": data["open_pr_count"],
                "draft_pr_count": data["draft_pr_count"],
                "pr_count_with_ai_bots": with_ai_bots,
                "pr_count_without_ai_bots": without_ai_bots,
                # Average days metrics - all and by status
                "avg_days_open_all": round(data["days_open_sum"] / total, 2) if total > 0 else 0,
                "avg_days_open_merged": (
                    round(data["days_open_merged_sum"] / merged, 2) if merged > 0 else 0
                ),
                "avg_days_open_closed": (
                    round(data["days_open_closed_sum"] / closed, 2) if closed > 0 else 0
                ),
                # Average days metrics - by AI bot presence
                "avg_days_open_with_ai_bots": (
                    round(data["days_open_with_ai_bots_sum"] / with_ai_bots, 2)
                    if with_ai_bots > 0
                    else 0
                ),
                "avg_days_open_without_ai_bots": (
                    round(data["days_open_without_ai_bots_sum"] / without_ai_bots, 2)
                    if without_ai_bots > 0
                    else 0
                ),
                "avg_days_in_review_all": (
                    round(data["days_in_review_sum"] / total, 2) if total > 0 else 0
                ),
                "avg_days_in_review_merged": (
                    round(data["days_in_review_merged_sum"] / merged, 2) if merged > 0 else 0
                ),
                "avg_days_in_review_with_ai_bots": (
                    round(data["days_in_review_with_ai_bots_sum"] / with_ai_bots, 2)
                    if with_ai_bots > 0
                    else 0
                ),
                "avg_days_in_review_without_ai_bots": (
                    round(data["days_in_review_without_ai_bots_sum"] / without_ai_bots, 2)
                    if without_ai_bots > 0
                    else 0
                ),
                # Comment/Review totals
                "total_comments": data["total_comments"],
                "total_non_ai_bot_comments": data["total_non_ai_bot_comments"],
                "total_ai_bot_comments": data["total_ai_bot_comments"],
                "total_changes_requested": data["total_changes_requested"],
                "total_approvals": data["total_approvals"],
                "avg_comments_per_pr": round(data["total_comments"] / total, 2) if total > 0 else 0,
                "avg_non_ai_bot_comments_per_pr": (
                    round(data["total_non_ai_bot_comments"] / total, 2) if total > 0 else 0
                ),
                # Code change totals
                "total_lines_added": data["total_lines_added"],
                "total_lines_deleted": data["total_lines_deleted"],
                "total_files_changed": data["total_files_changed"],
                "total_line_changes": data["total_line_changes"],
                "avg_lines_added_per_pr": (
                    round(data["total_lines_added"] / total, 2) if total > 0 else 0
                ),
                "avg_files_changed_per_pr": (
                    round(data["total_files_changed"] / total, 2) if total > 0 else 0
                ),
            }

            writer.writerow(row)

    print(f"Successfully created rollup: {rollup_file}")
    print(f"Total repositories: {len(rollup_data)}")


def main():
    if len(sys.argv) != 2:
        print("Usage: create-single-csv.sh <directory>", file=sys.stderr)
        sys.exit(1)

    input_dir = sys.argv[1]

    if not os.path.isdir(input_dir):
        print(f"Error: Directory '{input_dir}' not found", file=sys.stderr)
        sys.exit(1)

    output_file = "all-data.csv"
    csv_files = sorted(Path(input_dir).glob("*.csv"))

    if not csv_files:
        print(f"Error: No CSV files found in '{input_dir}'", file=sys.stderr)
        sys.exit(1)

    print(f"Merging {len(csv_files)} CSV files from: {input_dir}")

    header_written = False
    output_header = None
    rows_written = 0

    # Data structure for rollup: {(owner, repo): {metrics}}
    rollup_data = defaultdict(
        lambda: {
            "total_pr_count": 0,
            "merged_pr_count": 0,
            "closed_pr_count": 0,
            "open_pr_count": 0,
            "draft_pr_count": 0,
            "pr_count_with_ai_bots": 0,
            "pr_count_without_ai_bots": 0,
            "days_open_sum": 0.0,
            "days_open_merged_sum": 0.0,
            "days_open_closed_sum": 0.0,
            "days_open_with_ai_bots_sum": 0.0,
            "days_open_without_ai_bots_sum": 0.0,
            "days_in_review_sum": 0.0,
            "days_in_review_merged_sum": 0.0,
            "days_in_review_with_ai_bots_sum": 0.0,
            "days_in_review_without_ai_bots_sum": 0.0,
            "total_comments": 0,
            "total_non_ai_bot_comments": 0,
            "total_ai_bot_comments": 0,
            "total_changes_requested": 0,
            "total_approvals": 0,
            "total_lines_added": 0,
            "total_lines_deleted": 0,
            "total_files_changed": 0,
            "total_line_changes": 0,
        }
    )

    with open(output_file, "w", newline="", encoding="utf-8") as outfile:
        writer = None

        for csv_path in csv_files:
            # Extract owner and repo from filename
            filename = csv_path.stem  # filename without extension
            parts = filename.split("_", 1)  # split on first underscore

            if len(parts) == 2:
                owner, repo = parts
            else:
                # Fallback for files that don't match pattern
                owner = ""
                repo = filename

            try:
                with open(csv_path, "r", encoding="utf-8") as infile:
                    reader = csv.DictReader(infile)

                    # Initialize writer with header on first file
                    if not header_written:
                        output_header = ["owner", "repo"] + list(reader.fieldnames)
                        writer = csv.DictWriter(outfile, fieldnames=output_header)
                        writer.writeheader()
                        header_written = True

                    # Process rows: write to combined CSV and aggregate for rollup
                    for row in reader:
                        row["owner"] = owner
                        row["repo"] = repo
                        writer.writerow(row)
                        rows_written += 1

                        # Aggregate data for rollup
                        key = (owner, repo)
                        data = rollup_data[key]

                        status = row.get("status", "").lower()
                        days_open = safe_float(row.get("days_open"))
                        days_in_review = safe_float(row.get("days_in_review"))
                        ai_bot_count = int(safe_float(row.get("ai_bot_comment_count", 0)))
                        has_ai_bots = ai_bot_count > 0

                        # Count PRs by status
                        data["total_pr_count"] += 1
                        if status == "merged":
                            data["merged_pr_count"] += 1
                            data["days_open_merged_sum"] += days_open
                            data["days_in_review_merged_sum"] += days_in_review
                        elif status == "closed":
                            data["closed_pr_count"] += 1
                            data["days_open_closed_sum"] += days_open
                        elif status == "draft":
                            data["draft_pr_count"] += 1
                        elif status == "open":
                            data["open_pr_count"] += 1

                        # Count PRs by AI bot presence
                        if has_ai_bots:
                            data["pr_count_with_ai_bots"] += 1
                            data["days_open_with_ai_bots_sum"] += days_open
                            data["days_in_review_with_ai_bots_sum"] += days_in_review
                        else:
                            data["pr_count_without_ai_bots"] += 1
                            data["days_open_without_ai_bots_sum"] += days_open
                            data["days_in_review_without_ai_bots_sum"] += days_in_review

                        # Aggregate days metrics
                        data["days_open_sum"] += days_open
                        data["days_in_review_sum"] += days_in_review

                        # Aggregate comment/review metrics
                        data["total_comments"] += int(safe_float(row.get("total_comment_count", 0)))
                        data["total_non_ai_bot_comments"] += int(
                            safe_float(row.get("non_ai_bot_comment_count", 0))
                        )
                        data["total_ai_bot_comments"] += ai_bot_count
                        data["total_changes_requested"] += int(
                            safe_float(row.get("changes_requested_count", 0))
                        )
                        data["total_approvals"] += int(safe_float(row.get("approval_count", 0)))

                        # Aggregate code change metrics
                        data["total_lines_added"] += int(safe_float(row.get("lines_added", 0)))
                        data["total_lines_deleted"] += int(safe_float(row.get("lines_deleted", 0)))
                        data["total_files_changed"] += int(safe_float(row.get("files_changed", 0)))
                        data["total_line_changes"] += int(
                            safe_float(row.get("total_line_changes", 0))
                        )

            except Exception as e:
                print(f"Error processing {csv_path}: {e}", file=sys.stderr)
                continue

    print(f"Successfully merged {len(csv_files)} files into {output_file}")
    print(f"Total rows written: {rows_written}")

    # Create rollup CSV
    create_rollup(rollup_data)


if __name__ == "__main__":
    main()
