#!/usr/bin/env python3
# Generated By: Cursor (Claude Sonnet 4.5)
"""
Fetch Command Module

Fetches PR data from GitHub and caches as JSON.
"""

import argparse
from datetime import datetime, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed

from .base_command import BaseCommand
from data import PRFetcher


# Constants
MAX_CHUNK_DAYS = 30  # Maximum days to process in a single chunk
API_CALLS_PER_PR = 4  # Estimate: timeline, reviews, issue comments, review comments


class FetchCommand(BaseCommand):
    """
    Fetch PR data from GitHub and cache as JSON.

    Supports multiple modes:
    - Regular fetch with date range
    - Update single repo (fetch since last timestamp)
    - Update all tracked repos
    - Single PR fetch
    """

    def add_arguments(self, parser: argparse.ArgumentParser) -> None:
        """Add fetch-specific arguments."""
        parser.add_argument(
            "--owner",
            help="Repository owner",
        )
        parser.add_argument(
            "--repo",
            help="Repository name",
        )
        parser.add_argument(
            "--start",
            help="Start date (ISO 8601 format, e.g., 2024-01-01)",
        )
        parser.add_argument(
            "--end",
            help="End date (ISO 8601 format, defaults to today)",
        )
        parser.add_argument(
            "--update",
            action="store_true",
            help="Update mode: fetch since last timestamp from state file",
        )
        parser.add_argument(
            "--all",
            action="store_true",
            help="Fetch all tracked repositories",
        )
        parser.add_argument(
            "--pr",
            type=int,
            help="Fetch single PR by number",
        )
        parser.add_argument(
            "--wait",
            action="store_true",
            help="Wait for rate limit reset if quota exhausted (only with --all)",
        )
        parser.add_argument(
            "--workers",
            type=int,
            default=4,
            help="Number of parallel workers for PR fetching (default: 4)",
        )

    def run(self, args: argparse.Namespace) -> int:
        """
        Execute fetch command.

        Returns:
            Exit code (0 for success, non-zero for failure)
        """
        # Determine mode and validate arguments
        if args.all:
            return self._run_fetch_all(args)
        elif args.update:
            if not args.owner or not args.repo:
                self.logger.error("--update requires --owner and --repo")
                return 1
            return self._run_fetch_update(args)
        elif args.pr:
            if not args.owner or not args.repo:
                self.logger.error("--pr requires --owner and --repo")
                return 1
            return self._run_fetch_single_pr(args)
        else:
            # Regular fetch with date range
            if not args.owner or not args.repo or not args.start:
                self.logger.error("Regular fetch requires --owner, --repo, and --start")
                return 1
            return self._run_fetch_regular(args)

    def _run_fetch_regular(self, args: argparse.Namespace) -> int:
        """Regular fetch with explicit date range."""
        owner = args.owner
        repo = args.repo
        start_str = args.start
        end_str = args.end or datetime.now(timezone.utc).isoformat()

        # Parse dates
        try:
            from gh_pr_metrics import parse_timestamp

            start_date = parse_timestamp(start_str)
            end_date = parse_timestamp(end_str)
        except ValueError as e:
            self.logger.error("Invalid date: %s", e)
            return 1

        # Fetch repository
        return self._fetch_repository(owner, repo, start_date, end_date, args.workers)

    def _run_fetch_update(self, args: argparse.Namespace) -> int:
        """Update mode: fetch since last timestamp."""
        owner = args.owner
        repo = args.repo

        # Get last timestamp from state
        repo_state = self.state_manager.get_repo_state(owner, repo)
        if not repo_state or not repo_state.get("timestamp"):
            self.logger.error(
                "No state found for %s/%s. Use regular fetch or init first.", owner, repo
            )
            return 1

        start_date = repo_state["timestamp"]
        end_date = datetime.now(timezone.utc)

        self.logger.info("Updating %s/%s since %s", owner, repo, start_date.isoformat())

        return self._fetch_repository(owner, repo, start_date, end_date, args.workers)

    def _run_fetch_all(self, args: argparse.Namespace) -> int:
        """Fetch all tracked repositories."""
        repos = self.state_manager.get_all_tracked_repos()
        if not repos:
            self.logger.error("No tracked repositories found in state file")
            return 1

        self.logger.info("Fetching %d tracked repositories", len(repos))

        failed_repos = []
        for repo_info in repos:
            owner = repo_info["owner"]
            repo = repo_info["repo"]
            start_date = repo_info["timestamp"]
            end_date = datetime.now(timezone.utc)

            self.logger.info("Fetching %s/%s...", owner, repo)
            result = self._fetch_repository(owner, repo, start_date, end_date, args.workers)

            if result != 0:
                failed_repos.append(f"{owner}/{repo}")
                if not args.wait:
                    # Stop on first failure unless --wait specified
                    break

        if failed_repos:
            self.logger.error("Failed repositories: %s", ", ".join(failed_repos))
            return 1

        self.logger.info("Successfully fetched all tracked repositories")
        return 0

    def _run_fetch_single_pr(self, args: argparse.Namespace) -> int:
        """Fetch a single PR."""
        owner = args.owner
        repo = args.repo
        pr_number = args.pr

        self.logger.info("Fetching PR #%d from %s/%s", pr_number, owner, repo)

        # Create PR fetcher
        pr_fetcher = PRFetcher(
            self.github_client,
            self.quota_manager,
            self.config,
            self.logger,
            self.state_manager,
        )

        try:
            # Fetch the specific PR
            pr = self.github_client.make_request(
                f"https://api.github.com/repos/{owner}/{repo}/pulls/{pr_number}"
            )

            # Fetch and cache
            pr_fetcher.fetch_and_cache_pr(pr, owner, repo)

            self.logger.info("Successfully fetched PR #%d", pr_number)
            return 0

        except Exception as e:
            self.logger.error("Failed to fetch PR #%d: %s", pr_number, e)
            return 1

    def _fetch_repository(
        self, owner: str, repo: str, start_date: datetime, end_date: datetime, workers: int
    ) -> int:
        """
        Fetch all PRs for a repository in date range.

        Args:
            owner: Repository owner
            repo: Repository name
            start_date: Start date
            end_date: End date
            workers: Number of parallel workers

        Returns:
            Exit code (0 for success, non-zero for failure)
        """
        # Create PR fetcher
        pr_fetcher = PRFetcher(
            self.github_client,
            self.quota_manager,
            self.config,
            self.logger,
            self.state_manager,
        )

        try:
            # Fetch PR list
            self.logger.info(
                "Fetching PRs for %s/%s from %s to %s",
                owner,
                repo,
                start_date.isoformat(),
                end_date.isoformat(),
            )

            prs = pr_fetcher.fetch_pr_list(owner, repo, start_date, end_date)

            if not prs:
                self.logger.info("No PRs found in date range")
                # Update state with end date
                self.state_manager.update_repo(owner, repo, end_date, None)
                return 0

            self.logger.info("Found %d PRs to fetch", len(prs))

            # Check quota
            estimated_calls = len(prs) * API_CALLS_PER_PR
            sufficient, max_prs = self.quota_manager.check_sufficient(
                estimated_calls,
                f"{owner}/{repo}",
                "",
                lambda: self._get_github_token(),
                self.logger,
            )

            if not sufficient:
                self.logger.error("Insufficient API quota to process all PRs")
                return 1

            # Fetch PRs in parallel
            self.logger.info("Fetching PR details with %d workers...", workers)

            with ThreadPoolExecutor(max_workers=workers) as executor:
                futures = {
                    executor.submit(pr_fetcher.fetch_and_cache_pr, pr, owner, repo): pr
                    for pr in prs
                }

                completed = 0
                for future in as_completed(futures):
                    pr = futures[future]
                    try:
                        future.result()
                        completed += 1
                        if completed % 10 == 0 or completed == len(prs):
                            self.logger.info("Progress: %d/%d PRs fetched", completed, len(prs))
                    except Exception as e:
                        self.logger.error("Failed to fetch PR #%d: %s", pr["number"], e)

            # Update state with end date
            self.state_manager.update_repo(owner, repo, end_date, None)

            self.logger.info("Successfully fetched %d PRs", len(prs))
            return 0

        except Exception as e:
            self.logger.error("Failed to fetch repository: %s", e)
            return 1
