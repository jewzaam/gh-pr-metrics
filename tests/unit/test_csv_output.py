# Generated By: Cursor (Claude Sonnet 4.5)
"""Tests for CSV output generation."""

import csv
import io
from unittest import mock

import gh_pr_metrics


class TestCSVOutput:
    """Test CSV output generation."""

    def test_write_csv_to_stdout(self):
        """Test writing CSV to stdout."""
        metrics = [
            {
                "pr_number": 1,
                "title": "Test PR",
                "author": "testuser",
                "created_at": "2024-01-01T00:00:00Z",
                "ready_for_review_at": "2024-01-01T00:00:00Z",
                "merged_at": "",
                "closed_at": "",
                "total_comment_count": 5,
                "non_ai_bot_comment_count": 2,
                "ai_bot_comment_count": 1,
                "non_ai_bot_login_names": "dependabot[bot],github-actions[bot]",
                "ai_bot_login_names": "cursor[bot]",
                "changes_requested_count": 1,
                "unique_change_requesters": 1,
                "approval_count": 2,
                "status": "open",
                "url": "https://github.com/owner/repo/pull/1",
                "errors": "",
            }
        ]

        output = io.StringIO()
        with mock.patch("sys.stdout", output):
            gh_pr_metrics.csv_manager.write_csv(metrics, None)

        result = output.getvalue()
        assert "pr_number" in result
        assert "Test PR" in result
        assert "testuser" in result

    def test_write_csv_to_file(self, tmp_path):
        """Test writing CSV to a file."""
        metrics = [
            {
                "pr_number": 1,
                "title": "Test PR",
                "author": "testuser",
                "created_at": "2024-01-01T00:00:00Z",
                "ready_for_review_at": "2024-01-01T00:00:00Z",
                "merged_at": "",
                "closed_at": "",
                "total_comment_count": 5,
                "non_ai_bot_comment_count": 2,
                "ai_bot_comment_count": 0,
                "non_ai_bot_login_names": "github-actions[bot],sonarqubecloud[bot]",
                "ai_bot_login_names": "",
                "changes_requested_count": 1,
                "unique_change_requesters": 1,
                "approval_count": 2,
                "status": "open",
                "url": "https://github.com/owner/repo/pull/1",
                "errors": "",
            }
        ]

        output_file = tmp_path / "test.csv"
        gh_pr_metrics.csv_manager.write_csv(metrics, str(output_file))

        assert output_file.exists()
        content = output_file.read_text()
        assert "pr_number" in content
        assert "Test PR" in content

    def test_write_csv_with_special_characters(self, tmp_path):
        """Test CSV output handles special characters properly."""
        metrics = [
            {
                "pr_number": 1,
                "title": 'Test "PR" with, commas',
                "author": "testuser",
                "created_at": "2024-01-01T00:00:00Z",
                "ready_for_review_at": "2024-01-01T00:00:00Z",
                "merged_at": "",
                "closed_at": "",
                "total_comment_count": 0,
                "non_ai_bot_comment_count": 0,
                "ai_bot_comment_count": 0,
                "non_ai_bot_login_names": "",
                "ai_bot_login_names": "",
                "changes_requested_count": 0,
                "unique_change_requesters": 0,
                "approval_count": 0,
                "status": "open",
                "url": "https://github.com/owner/repo/pull/1",
                "errors": "",
            }
        ]

        output_file = tmp_path / "test.csv"
        gh_pr_metrics.csv_manager.write_csv(metrics, str(output_file))

        # Read back and verify CSV is valid
        with open(output_file, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            rows = list(reader)
            assert len(rows) == 1
            assert rows[0]["title"] == 'Test "PR" with, commas'

    def test_write_csv_empty_metrics(self):
        """Test handling of empty metrics list."""
        output = io.StringIO()
        with mock.patch("sys.stdout", output):
            gh_pr_metrics.csv_manager.write_csv([], None)

        result = output.getvalue()
        # Should not write anything for empty metrics
        assert result == ""

    def test_write_csv_with_merged_and_closed_timestamps(self, tmp_path):
        """Test CSV output includes merged_at and closed_at timestamps."""
        metrics = [
            {
                "pr_number": 1,
                "title": "Merged PR",
                "author": "testuser",
                "created_at": "2024-01-01T00:00:00Z",
                "ready_for_review_at": "2024-01-01T00:00:00Z",
                "merged_at": "2024-01-05T12:00:00Z",
                "closed_at": "2024-01-05T12:00:00Z",
                "total_comment_count": 3,
                "non_ai_bot_comment_count": 0,
                "ai_bot_comment_count": 1,
                "non_ai_bot_login_names": "",
                "ai_bot_login_names": "cursor[bot]",
                "changes_requested_count": 0,
                "unique_change_requesters": 0,
                "approval_count": 2,
                "status": "merged",
                "url": "https://github.com/owner/repo/pull/1",
                "errors": "",
            }
        ]

        output_file = tmp_path / "test.csv"
        gh_pr_metrics.csv_manager.write_csv(metrics, str(output_file))

        # Read back and verify CSV contains the timestamps
        with open(output_file, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            rows = list(reader)
            assert len(rows) == 1
            assert rows[0]["merged_at"] == "2024-01-05T12:00:00Z"
            assert rows[0]["closed_at"] == "2024-01-05T12:00:00Z"

    def test_read_existing_csv(self, tmp_path):
        """Test reading existing CSV file."""
        # Create a CSV file
        csv_file = tmp_path / "existing.csv"
        with open(csv_file, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=["pr_number", "title", "status"])
            writer.writeheader()
            writer.writerow({"pr_number": "1", "title": "PR 1", "status": "open"})
            writer.writerow({"pr_number": "2", "title": "PR 2", "status": "merged"})

        # Read it back
        data = gh_pr_metrics.csv_manager.read_csv(str(csv_file))
        assert len(data) == 2
        assert 1 in data
        assert 2 in data
        assert data[1]["title"] == "PR 1"
        assert data[2]["title"] == "PR 2"

    def test_read_existing_csv_nonexistent(self, tmp_path):
        """Test reading non-existent CSV returns empty dict."""
        csv_file = tmp_path / "nonexistent.csv"
        data = gh_pr_metrics.csv_manager.read_csv(str(csv_file))
        assert data == {}

    def test_write_csv_merge_mode_add_new(self, tmp_path):
        """Test merge mode adds new PRs to existing CSV."""
        csv_file = tmp_path / "test.csv"

        # Create initial CSV with PR 1
        initial_metrics = [
            {
                "pr_number": 1,
                "title": "Original PR",
                "author": "user1",
                "created_at": "2024-01-01T00:00:00Z",
                "ready_for_review_at": "2024-01-01T00:00:00Z",
                "merged_at": "",
                "closed_at": "",
                "total_comment_count": 0,
                "non_ai_bot_comment_count": 0,
                "ai_bot_comment_count": 0,
                "non_ai_bot_login_names": "",
                "ai_bot_login_names": "",
                "changes_requested_count": 0,
                "unique_change_requesters": 0,
                "approval_count": 0,
                "status": "open",
                "url": "https://github.com/owner/repo/pull/1",
                "errors": "",
            }
        ]
        gh_pr_metrics.csv_manager.write_csv(initial_metrics, str(csv_file))

        # Add PR 2 in merge mode
        new_metrics = [
            {
                "pr_number": 2,
                "title": "New PR",
                "author": "user2",
                "created_at": "2024-01-02T00:00:00Z",
                "ready_for_review_at": "2024-01-02T00:00:00Z",
                "merged_at": "",
                "closed_at": "",
                "total_comment_count": 0,
                "non_ai_bot_comment_count": 0,
                "ai_bot_comment_count": 0,
                "non_ai_bot_login_names": "",
                "ai_bot_login_names": "",
                "changes_requested_count": 0,
                "unique_change_requesters": 0,
                "approval_count": 0,
                "status": "open",
                "url": "https://github.com/owner/repo/pull/2",
                "errors": "",
            }
        ]
        gh_pr_metrics.csv_manager.write_csv(new_metrics, str(csv_file), merge_mode=True)

        # Verify both PRs are in the file
        with open(csv_file, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            rows = list(reader)
            assert len(rows) == 2
            pr_numbers = {int(row["pr_number"]) for row in rows}
            assert pr_numbers == {1, 2}

    def test_write_csv_merge_mode_update_existing(self, tmp_path):
        """Test merge mode updates existing PR in CSV."""
        csv_file = tmp_path / "test.csv"

        # Create initial CSV with PR 1 (open)
        initial_metrics = [
            {
                "pr_number": 1,
                "title": "Original PR",
                "author": "user1",
                "created_at": "2024-01-01T00:00:00Z",
                "ready_for_review_at": "2024-01-01T00:00:00Z",
                "merged_at": "",
                "closed_at": "",
                "total_comment_count": 0,
                "non_ai_bot_comment_count": 0,
                "ai_bot_comment_count": 0,
                "non_ai_bot_login_names": "",
                "ai_bot_login_names": "",
                "changes_requested_count": 0,
                "unique_change_requesters": 0,
                "approval_count": 0,
                "status": "open",
                "url": "https://github.com/owner/repo/pull/1",
                "errors": "",
            }
        ]
        gh_pr_metrics.csv_manager.write_csv(initial_metrics, str(csv_file))

        # Update PR 1 (now merged) in merge mode
        updated_metrics = [
            {
                "pr_number": 1,
                "title": "Original PR",
                "author": "user1",
                "created_at": "2024-01-01T00:00:00Z",
                "ready_for_review_at": "2024-01-01T00:00:00Z",
                "merged_at": "2024-01-03T00:00:00Z",
                "closed_at": "2024-01-03T00:00:00Z",
                "total_comment_count": 5,
                "non_ai_bot_comment_count": 3,
                "ai_bot_comment_count": 2,
                "non_ai_bot_login_names": "",
                "ai_bot_login_names": "cursor[bot]",
                "changes_requested_count": 1,
                "unique_change_requesters": 1,
                "approval_count": 2,
                "status": "merged",
                "url": "https://github.com/owner/repo/pull/1",
                "errors": "",
            }
        ]
        gh_pr_metrics.csv_manager.write_csv(updated_metrics, str(csv_file), merge_mode=True)

        # Verify PR 1 is updated
        with open(csv_file, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            rows = list(reader)
            assert len(rows) == 1
            assert rows[0]["status"] == "merged"
            assert rows[0]["merged_at"] == "2024-01-03T00:00:00Z"
            assert rows[0]["total_comment_count"] == "5"
