# GitHub Pull Request Metrics Tool

Generated By: Cursor (Claude Sonnet 4.5)

A command-line tool to generate CSV reports containing key metrics for all pull requests in a GitHub repository within a specified time range.

## What It Does

Analyzes GitHub pull requests and generates CSV reports with metrics including:
- PR creation, ready-for-review, merged, and closed timestamps
- Comment counts (total and bot-specific)
- Change request counts (total and unique reviewers)
- Approval counts and PR status
- **Differential updates**: Update existing CSV files by fetching only new PRs since last run

## Installation

```bash
make install
```

This installs the `gh-pr-metrics` command to `~/.local/bin` (ensure it's in your PATH).

## Usage

```bash
# Show help
gh-pr-metrics --help

# Basic usage (auto-detects current repo, analyzes last 365 days)
gh-pr-metrics

# Public repository example (no token required)
gh-pr-metrics --owner ansible --repo awx --start 2025-11-01 --end 2025-11-05 --output /tmp/awx-metrics.csv

# Custom AI bot pattern (match multiple AI bots)
gh-pr-metrics --ai-bot-regex "cursor\\[bot\\]|copilot\\[bot\\]"

# Disable AI bot detection (treat all bots as non-AI)
gh-pr-metrics --ai-bot-regex ""
```

### Differential Updates

For daily or frequent runs, use `--update` to fetch only new PRs since the last run. The state file automatically tracks which CSV file belongs to each repository.

```bash
# First run: creates CSV and stores path in state file (~/.gh-pr-metrics-state.yaml)
gh-pr-metrics --owner org1 --repo repo1 --output org1-repo1.csv
gh-pr-metrics --owner org2 --repo repo2 --output org2-repo2.csv

# Update specific repository (uses stored CSV path)
gh-pr-metrics --owner org1 --repo repo1 --update

# Update ALL tracked repositories at once
gh-pr-metrics --update

# Outputs to stdout don't get tracked (no state saved)
gh-pr-metrics --owner org --repo repo  # No --output = no tracking
```

**Benefits of `--update` mode:**
- Significantly reduces API calls (avoids throttling)
- Faster execution on large repositories
- Automatically tracks last update date AND CSV path per repository
- Updates existing PRs in CSV if their status changed
- Update all repos with single command
- Ideal for daily/scheduled runs across hundreds of repositories

**Automatic chunking for large date ranges:**
- Date ranges > 30 days are automatically split into 30-day chunks with 1-day overlap
- Overlap prevents data loss at chunk boundaries (PRs deduplicated automatically)
- Rate limit checked before processing each chunk
- Progress saved after each chunk (can resume with `--update` or `--update-all` if stopped)
- Prevents rate limit exhaustion on historical backfills
- Duplicate PRs in overlaps are skipped (saves ~3% API calls)

**State tracking**: The state file `~/.gh-pr-metrics-state.yaml` stores both the last update timestamp and CSV file path for each repository.

```yaml
# Example state file
https://github.com/owner/repo:
  csv_file: /path/to/metrics.csv
  timestamp: '2024-11-20T15:30:00'
https://github.com/org1/repo1:
  csv_file: /path/to/org1-repo1.csv
  timestamp: '2024-11-21T08:00:00'
```

**Note**: `--update` and `--output` cannot be used together. Update mode always uses the CSV path stored in the state file.

### Authentication

Set `GITHUB_TOKEN` environment variable for private repositories or to avoid rate limits:

**Note:** Without a token, the tool automatically uses `--workers=1` to reduce API load for unauthenticated rate limit (60 requests/hour).

## CSV Output

Example output:

```csv
pr_number,title,author,created_at,ready_for_review_at,merged_at,closed_at,total_comment_count,non_ai_bot_comment_count,ai_bot_comment_count,non_ai_bot_login_names,ai_bot_login_names,changes_requested_count,unique_change_requesters,approval_count,status,url,errors
123,"Fix bug",user1,2024-01-15T10:30:00Z,2024-01-15T14:20:00Z,2024-01-16T09:00:00Z,2024-01-16T09:00:00Z,15,2,1,"dependabot[bot],github-actions[bot]",cursor[bot],2,2,3,merged,https://github.com/owner/repo/pull/123,
124,"Add feature",user2,2024-01-16T09:15:00Z,,,,8,1,0,sonarqubecloud[bot],,0,0,1,open,https://github.com/owner/repo/pull/124,
```

### Column Descriptions

- `pr_number` - Pull request number
- `title` - Pull request title
- `author` - Pull request author username
- `created_at` - ISO 8601 timestamp when PR was created
- `ready_for_review_at` - ISO 8601 timestamp when PR was marked ready (empty for draft PRs)
- `merged_at` - ISO 8601 timestamp when PR was merged (empty if not merged)
- `closed_at` - ISO 8601 timestamp when PR was closed (empty if still open)
- `total_comment_count` - Total comments (includes all bot and human comments)
- `non_ai_bot_comment_count` - Non-AI bot comments only (excludes AI bots and humans)
- `ai_bot_comment_count` - AI bot comments only (currently tracks cursor[bot])
- `non_ai_bot_login_names` - Comma-separated list of non-AI bot logins that commented
- `ai_bot_login_names` - Comma-separated list of AI bot logins that commented
- `changes_requested_count` - Total change requests submitted
- `unique_change_requesters` - Unique reviewers who requested changes
- `approval_count` - Current approval count (latest state per reviewer)
- `status` - One of: draft, open, closed, merged
- `url` - Full URL to the pull request
- `errors` - Error messages if data collection failed (usually empty)

## Contributing

Development workflow:

```bash
# Install development dependencies
make requirements-dev

# Code quality checks
make format    # Auto-format code with black
make lint      # Check code with ruff
make test      # Run unit tests
make coverage  # Verify 70%+ test coverage
```

### Contribution Guidelines

1. Follow PEP 8 style (enforced by `ruff`)
2. Add tests for new features
3. Ensure `make format lint test coverage` passes
4. Include `Assisted-by: <Tool> (<Model>)` in commit messages
5. Add `Generated By: <Tool> (<Model>)` to new file headers

### Requirements

- Python 3.10+
- GitHub.com repositories (GitHub Enterprise not supported)

