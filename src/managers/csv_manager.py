#!/usr/bin/env python3
# Generated By: Cursor (Claude Sonnet 4.5)
"""
CSV Management Module

Handles CSV file I/O operations for PR metrics.
Thread-safe for concurrent access.
"""

import csv
import os
import sys
import tempfile
import threading
from pathlib import Path
from typing import List, Dict, Any, Optional


# PR number field constant
PR_NUMBER_FIELD = "pr_number"


def with_lock(func):
    """Decorator to synchronize access to CSVManager methods using self._lock."""

    def wrapper(self, *args, **kwargs):
        with self._lock:
            return func(self, *args, **kwargs)

    return wrapper


class CSVManager:
    """
    Manages CSV I/O operations for PR metrics.

    Handles reading existing CSV files, writing metrics data,
    and managing field definitions. Thread-safe for concurrent access.
    """

    def __init__(self, logger=None):
        """Initialize CSV manager with logger."""
        self._logger = logger
        self._lock = threading.RLock()

    def get_fieldnames(self) -> List[str]:
        """Get CSV field names in order."""
        return [
            PR_NUMBER_FIELD,
            "title",
            "author",
            "created_at",
            "ready_for_review_at",
            "merged_at",
            "closed_at",
            "days_open",
            "days_in_review",
            "total_comment_count",
            "non_ai_bot_comment_count",
            "ai_bot_comment_count",
            "non_ai_bot_login_names",
            "ai_bot_login_names",
            "changes_requested_count",
            "unique_change_requesters",
            "approval_count",
            "status",
            "url",
            "errors",
            "lines_added",
            "lines_deleted",
            "files_changed",
            "total_line_changes",
        ]

    @with_lock
    def read_csv(self, csv_file: str) -> Dict[int, Dict[str, Any]]:
        """
        Read existing CSV file and return dict keyed by PR number (thread-safe).
        Returns empty dict if file doesn't exist or can't be read.
        """
        if not os.path.exists(csv_file):
            return {}

        try:
            existing_data = {}
            with open(csv_file, "r", newline="", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    # Key by PR number for O(1) lookups
                    pr_number = int(row[PR_NUMBER_FIELD])
                    existing_data[pr_number] = row

            if self._logger:
                self._logger.debug("Loaded %d existing PRs from %s", len(existing_data), csv_file)
            return existing_data
        except Exception as e:
            if self._logger:
                self._logger.warning("Failed to read existing CSV %s: %s", csv_file, e)
            return {}

    @with_lock
    def write_csv(
        self,
        metrics: List[Dict[str, Any]],
        output_file: Optional[str],
        merge_mode: bool = False,
        force_write: bool = False,
    ) -> None:
        """
        Write metrics to CSV file or stdout (thread-safe).

        If merge_mode is True and output_file exists, existing PR data is loaded,
        updated with new metrics, and written back.

        If force_write is True, write headers even if metrics list is empty.
        """
        if not metrics and not force_write:
            if self._logger:
                self._logger.warning("No pull requests to output")
            return

        fieldnames = self.get_fieldnames()

        # Merge with existing data if requested
        if merge_mode and output_file:
            # Re-read inside lock to get latest data
            if not os.path.exists(output_file):
                existing_data = {}
            else:
                try:
                    existing_data = {}
                    with open(output_file, "r", newline="", encoding="utf-8") as f:
                        reader = csv.DictReader(f)
                        for row in reader:
                            pr_number = int(row[PR_NUMBER_FIELD])
                            existing_data[pr_number] = row
                except Exception:
                    existing_data = {}

            # Update existing data with new metrics
            for metric in metrics:
                pr_number = metric[PR_NUMBER_FIELD]
                existing_data[pr_number] = metric

            # Convert back to list
            all_metrics = list(existing_data.values())
            if self._logger:
                self._logger.debug(
                    "Merged data: %d total PRs (%d new/updated)", len(all_metrics), len(metrics)
                )
        else:
            all_metrics = metrics

        if output_file:
            # Write to temp file first, then atomically rename
            output_path = Path(output_file)
            temp_fd, temp_path = tempfile.mkstemp(
                dir=(output_path.parent if output_path.parent.exists() else tempfile.gettempdir()),
                prefix=".tmp_pr_metrics_",
                suffix=".csv",
            )

            try:
                with os.fdopen(temp_fd, "w", newline="", encoding="utf-8") as f:
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(all_metrics)

                # Atomic rename
                os.rename(temp_path, output_file)
                if self._logger:
                    self._logger.debug("Wrote %d PRs to %s", len(all_metrics), output_file)
            except Exception as e:
                # Keep temp file for debugging
                if self._logger:
                    self._logger.error(
                        "Failed to write CSV output. Temp file retained at: %s", temp_path
                    )
                raise e
        else:
            writer = csv.DictWriter(sys.stdout, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_metrics)
