# Generated By: Cursor (Claude Sonnet 4.5)
"""Tests for gh_pr_extract_comments module."""

import json
import logging
import sys
from datetime import datetime, timezone
from pathlib import Path
from unittest import mock

import pytest
import yaml

import gh_pr_extract_comments
from github_api import GitHubAPIError


class TestSetupLogging:
    """Test logging configuration."""

    def test_setup_logging_default(self):
        """Test default logging setup (INFO level)."""
        # Reset logger first
        logger = logging.getLogger()
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)

        gh_pr_extract_comments.setup_logging(debug=False)
        assert logger.level == logging.INFO

    def test_setup_logging_debug(self):
        """Test debug logging setup (DEBUG level)."""
        # Reset logger first
        logger = logging.getLogger()
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)

        gh_pr_extract_comments.setup_logging(debug=True)
        assert logger.level == logging.DEBUG


class TestLoadStateFile:
    """Test state file loading."""

    def test_load_state_file_nonexistent(self, tmp_path):
        """Test loading nonexistent state file returns empty dict."""
        state_file = tmp_path / "nonexistent.yaml"
        result = gh_pr_extract_comments.load_state_file(state_file)
        assert result == {}

    def test_load_state_file_empty(self, tmp_path):
        """Test loading empty state file returns empty dict."""
        state_file = tmp_path / "state.yaml"
        state_file.write_text("", encoding="utf-8")
        result = gh_pr_extract_comments.load_state_file(state_file)
        assert result == {}

    def test_load_state_file_valid(self, tmp_path):
        """Test loading valid state file."""
        state_file = tmp_path / "state.yaml"
        state_data = {
            "https://github.com/owner/repo": {
                "csv_file": "/path/to/file.csv",
                "query_time": "2024-01-01T00:00:00Z",
            }
        }
        state_file.write_text(yaml.dump(state_data), encoding="utf-8")

        result = gh_pr_extract_comments.load_state_file(state_file)
        assert result == state_data

    def test_load_state_file_invalid_yaml(self, tmp_path):
        """Test loading invalid YAML returns empty dict."""
        state_file = tmp_path / "state.yaml"
        state_file.write_text("invalid: yaml: content:\n  - broken", encoding="utf-8")

        result = gh_pr_extract_comments.load_state_file(state_file)
        assert result == {}


class TestGetTrackedReposWithCsv:
    """Test tracked repository discovery."""

    def test_no_repos_when_state_empty(self, tmp_path):
        """Test returns empty list when state file is empty."""
        state_file = tmp_path / "state.yaml"
        state_file.write_text("", encoding="utf-8")
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()

        repos = gh_pr_extract_comments.get_tracked_repos_with_csv(state_file, csv_dir)
        assert repos == []

    def test_skips_repos_without_csv_file(self, tmp_path):
        """Test skips repositories without CSV file in state."""
        state_file = tmp_path / "state.yaml"
        state_data = {
            "https://github.com/owner/repo": {
                "query_time": "2024-01-01T00:00:00Z",
            }
        }
        state_file.write_text(yaml.dump(state_data), encoding="utf-8")
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()

        repos = gh_pr_extract_comments.get_tracked_repos_with_csv(state_file, csv_dir)
        assert repos == []

    def test_skips_repos_with_missing_csv_file(self, tmp_path):
        """Test skips repositories where CSV file doesn't exist."""
        state_file = tmp_path / "state.yaml"
        csv_file = tmp_path / "missing.csv"
        state_data = {
            "https://github.com/owner/repo": {
                "csv_file": str(csv_file),
                "query_time": "2024-01-01T00:00:00Z",
            }
        }
        state_file.write_text(yaml.dump(state_data), encoding="utf-8")
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()

        repos = gh_pr_extract_comments.get_tracked_repos_with_csv(state_file, csv_dir)
        assert repos == []

    def test_returns_repos_with_existing_csv(self, tmp_path):
        """Test returns repositories with existing CSV files."""
        state_file = tmp_path / "state.yaml"
        csv_file = tmp_path / "repo.csv"
        csv_file.write_text("", encoding="utf-8")  # Create empty CSV

        state_data = {
            "https://github.com/owner/repo": {
                "csv_file": str(csv_file),
                "query_time": "2024-01-01T00:00:00Z",
            }
        }
        state_file.write_text(yaml.dump(state_data), encoding="utf-8")
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()

        repos = gh_pr_extract_comments.get_tracked_repos_with_csv(state_file, csv_dir)
        assert len(repos) == 1
        assert repos[0]["owner"] == "owner"
        assert repos[0]["repo"] == "repo"
        assert repos[0]["csv_file"] == str(csv_file)

    def test_skips_invalid_state_format(self, tmp_path):
        """Test skips entries with invalid state format."""
        state_file = tmp_path / "state.yaml"
        state_data = {
            "https://github.com/owner/repo": "invalid_string_format",
        }
        state_file.write_text(yaml.dump(state_data), encoding="utf-8")
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()

        repos = gh_pr_extract_comments.get_tracked_repos_with_csv(state_file, csv_dir)
        assert repos == []

    def test_handles_malformed_urls(self, tmp_path):
        """Test handles malformed repository URLs gracefully."""
        state_file = tmp_path / "state.yaml"
        state_data = {
            "invalid-url": {
                "csv_file": "/path/to/file.csv",
            }
        }
        state_file.write_text(yaml.dump(state_data), encoding="utf-8")
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()

        repos = gh_pr_extract_comments.get_tracked_repos_with_csv(state_file, csv_dir)
        assert repos == []


class TestReadPrsFromCsv:
    """Test reading PRs from CSV files."""

    def test_returns_empty_list_for_nonexistent_file(self):
        """Test returns empty list when CSV file doesn't exist."""
        start_date = datetime(2024, 1, 1, tzinfo=timezone.utc)
        result = gh_pr_extract_comments.read_prs_from_csv("/nonexistent.csv", start_date, 5)
        assert result == []

    def test_reads_prs_from_valid_csv(self, tmp_path):
        """Test reads PRs from valid CSV file."""
        csv_file = tmp_path / "test.csv"
        csv_content = """pr_number,created_at,updated_at
1,2024-01-15T10:00:00Z,2024-01-15T12:00:00Z
2,2024-01-10T10:00:00Z,2024-01-10T12:00:00Z
3,2024-01-05T10:00:00Z,2024-01-05T12:00:00Z
"""
        csv_file.write_text(csv_content, encoding="utf-8")

        start_date = datetime(2024, 1, 1, tzinfo=timezone.utc)
        result = gh_pr_extract_comments.read_prs_from_csv(str(csv_file), start_date, 5)

        assert len(result) == 3
        assert result[0]["pr_number"] == 1  # Most recent first
        assert result[1]["pr_number"] == 2
        assert result[2]["pr_number"] == 3

    def test_filters_by_start_date(self, tmp_path):
        """Test filters PRs by start date."""
        csv_file = tmp_path / "test.csv"
        csv_content = """pr_number,created_at,updated_at
1,2024-01-15T10:00:00Z,2024-01-15T12:00:00Z
2,2024-01-10T10:00:00Z,2024-01-10T12:00:00Z
3,2023-12-25T10:00:00Z,2023-12-25T12:00:00Z
"""
        csv_file.write_text(csv_content, encoding="utf-8")

        start_date = datetime(2024, 1, 1, tzinfo=timezone.utc)
        result = gh_pr_extract_comments.read_prs_from_csv(str(csv_file), start_date, 5)

        assert len(result) == 2
        assert result[0]["pr_number"] == 1
        assert result[1]["pr_number"] == 2

    def test_limits_count(self, tmp_path):
        """Test returns only requested count of PRs."""
        csv_file = tmp_path / "test.csv"
        csv_content = """pr_number,created_at,updated_at
1,2024-01-15T10:00:00Z,2024-01-15T12:00:00Z
2,2024-01-10T10:00:00Z,2024-01-10T12:00:00Z
3,2024-01-05T10:00:00Z,2024-01-05T12:00:00Z
"""
        csv_file.write_text(csv_content, encoding="utf-8")

        start_date = datetime(2024, 1, 1, tzinfo=timezone.utc)
        result = gh_pr_extract_comments.read_prs_from_csv(str(csv_file), start_date, 2)

        assert len(result) == 2
        assert result[0]["pr_number"] == 1
        assert result[1]["pr_number"] == 2

    def test_skips_rows_without_created_at(self, tmp_path):
        """Test skips rows without created_at field."""
        csv_file = tmp_path / "test.csv"
        csv_content = """pr_number,created_at,updated_at
1,2024-01-15T10:00:00Z,2024-01-15T12:00:00Z
2,,2024-01-10T12:00:00Z
3,2024-01-05T10:00:00Z,2024-01-05T12:00:00Z
"""
        csv_file.write_text(csv_content, encoding="utf-8")

        start_date = datetime(2024, 1, 1, tzinfo=timezone.utc)
        result = gh_pr_extract_comments.read_prs_from_csv(str(csv_file), start_date, 5)

        assert len(result) == 2
        assert result[0]["pr_number"] == 1
        assert result[1]["pr_number"] == 3

    def test_skips_rows_with_invalid_dates(self, tmp_path):
        """Test skips rows with invalid date formats."""
        csv_file = tmp_path / "test.csv"
        csv_content = """pr_number,created_at,updated_at
1,2024-01-15T10:00:00Z,2024-01-15T12:00:00Z
2,invalid-date,2024-01-10T12:00:00Z
3,2024-01-05T10:00:00Z,2024-01-05T12:00:00Z
"""
        csv_file.write_text(csv_content, encoding="utf-8")

        start_date = datetime(2024, 1, 1, tzinfo=timezone.utc)
        result = gh_pr_extract_comments.read_prs_from_csv(str(csv_file), start_date, 5)

        assert len(result) == 2
        assert result[0]["pr_number"] == 1
        assert result[1]["pr_number"] == 3

    def test_handles_naive_timestamps(self, tmp_path):
        """Test handles naive timestamps by making them UTC."""
        csv_file = tmp_path / "test.csv"
        csv_content = """pr_number,created_at,updated_at
1,2024-01-15T10:00:00,2024-01-15T12:00:00
"""
        csv_file.write_text(csv_content, encoding="utf-8")

        start_date = datetime(2024, 1, 1, tzinfo=timezone.utc)
        result = gh_pr_extract_comments.read_prs_from_csv(str(csv_file), start_date, 5)

        assert len(result) == 1
        assert result[0]["created_at"].tzinfo is not None

    def test_handles_read_error(self, tmp_path):
        """Test handles CSV read errors gracefully."""
        csv_file = tmp_path / "test.csv"
        csv_file.write_text("invalid,csv,format\nno,pr_number,field", encoding="utf-8")

        start_date = datetime(2024, 1, 1, tzinfo=timezone.utc)
        result = gh_pr_extract_comments.read_prs_from_csv(str(csv_file), start_date, 5)

        assert result == []


class TestFetchPrDetails:
    """Test fetching PR details."""

    def test_fetches_complete_pr_details(self):
        """Test fetches complete PR details including comments and reviews."""
        mock_client = mock.Mock()
        mock_client.fetch_single_pr.return_value = {
            "number": 123,
            "title": "Test PR",
            "user": {"login": "testuser", "type": "User"},
            "state": "open",
            "created_at": "2024-01-01T00:00:00Z",
            "updated_at": "2024-01-02T00:00:00Z",
            "merged_at": None,
            "closed_at": None,
            "draft": False,
            "html_url": "https://github.com/owner/repo/pull/123",
            "additions": 10,
            "deletions": 5,
            "changed_files": 2,
            "comments_url": "https://api.github.com/repos/owner/repo/issues/123/comments",
            "review_comments_url": "https://api.github.com/repos/owner/repo/pulls/123/comments",
        }

        mock_client.fetch_issue_comments.return_value = [
            {
                "id": 1,
                "user": {"login": "commenter", "type": "User"},
                "body": "Comment text",
                "created_at": "2024-01-01T10:00:00Z",
                "updated_at": "2024-01-01T10:00:00Z",
            }
        ]

        mock_client.fetch_review_comments.return_value = [
            {
                "id": 2,
                "user": {"login": "reviewer", "type": "User"},
                "body": "Review comment",
                "path": "file.py",
                "line": 10,
                "created_at": "2024-01-01T11:00:00Z",
                "updated_at": "2024-01-01T11:00:00Z",
            }
        ]

        mock_client.fetch_reviews.return_value = [
            {
                "id": 3,
                "user": {"login": "reviewer", "type": "User"},
                "state": "APPROVED",
                "body": "LGTM",
                "submitted_at": "2024-01-01T12:00:00Z",
            }
        ]

        result = gh_pr_extract_comments.fetch_pr_details(mock_client, "owner", "repo", 123)

        assert result is not None
        assert result["pr_number"] == 123
        assert result["title"] == "Test PR"
        assert result["author"] == "testuser"
        assert len(result["issue_comments"]) == 1
        assert len(result["review_comments"]) == 1
        assert len(result["reviews"]) == 1

    def test_handles_missing_comments_gracefully(self):
        """Test handles API errors when fetching comments."""
        mock_client = mock.Mock()
        mock_client.fetch_single_pr.return_value = {
            "number": 123,
            "title": "Test PR",
            "user": {"login": "testuser", "type": "User"},
            "state": "open",
            "created_at": "2024-01-01T00:00:00Z",
            "updated_at": "2024-01-02T00:00:00Z",
            "html_url": "https://github.com/owner/repo/pull/123",
            "comments_url": "https://api.github.com/repos/owner/repo/issues/123/comments",
            "review_comments_url": "https://api.github.com/repos/owner/repo/pulls/123/comments",
        }

        mock_client.fetch_issue_comments.side_effect = GitHubAPIError("API Error", 500)
        mock_client.fetch_review_comments.side_effect = GitHubAPIError("API Error", 500)
        mock_client.fetch_reviews.side_effect = GitHubAPIError("API Error", 500)

        result = gh_pr_extract_comments.fetch_pr_details(mock_client, "owner", "repo", 123)

        assert result is not None
        assert result["pr_number"] == 123
        assert len(result["issue_comments"]) == 0
        assert len(result["review_comments"]) == 0
        assert len(result["reviews"]) == 0

    def test_returns_none_on_pr_fetch_error(self):
        """Test returns None when PR fetch fails."""
        mock_client = mock.Mock()
        mock_client.fetch_single_pr.side_effect = GitHubAPIError("Not found", 404)

        result = gh_pr_extract_comments.fetch_pr_details(mock_client, "owner", "repo", 123)

        assert result is None

    def test_includes_all_pr_fields(self):
        """Test includes all expected PR fields."""
        mock_client = mock.Mock()
        mock_client.fetch_single_pr.return_value = {
            "number": 123,
            "title": "Test PR",
            "user": {"login": "testuser", "type": "User"},
            "state": "closed",
            "created_at": "2024-01-01T00:00:00Z",
            "updated_at": "2024-01-02T00:00:00Z",
            "merged_at": "2024-01-02T10:00:00Z",
            "closed_at": "2024-01-02T10:00:00Z",
            "draft": True,
            "html_url": "https://github.com/owner/repo/pull/123",
            "additions": 100,
            "deletions": 50,
            "changed_files": 10,
            "comments_url": "https://api.github.com/repos/owner/repo/issues/123/comments",
            "review_comments_url": "https://api.github.com/repos/owner/repo/pulls/123/comments",
        }

        mock_client.fetch_issue_comments.return_value = []
        mock_client.fetch_review_comments.return_value = []
        mock_client.fetch_reviews.return_value = []

        result = gh_pr_extract_comments.fetch_pr_details(mock_client, "owner", "repo", 123)

        assert result["pr_number"] == 123
        assert result["title"] == "Test PR"
        assert result["author"] == "testuser"
        assert result["author_type"] == "User"
        assert result["state"] == "closed"
        assert result["merged_at"] == "2024-01-02T10:00:00Z"
        assert result["closed_at"] == "2024-01-02T10:00:00Z"
        assert result["draft"] is True
        assert result["additions"] == 100
        assert result["deletions"] == 50
        assert result["changed_files"] == 10


class TestWritePrJson:
    """Test writing PR data to JSON."""

    def test_creates_nested_directory_structure(self, tmp_path):
        """Test creates nested owner/repo directory structure."""
        output_dir = tmp_path / "output"
        pr_data = {
            "pr_number": 123,
            "title": "Test PR",
        }

        gh_pr_extract_comments.write_pr_json(output_dir, "owner", "repo", pr_data)

        expected_dir = output_dir / "owner" / "repo"
        assert expected_dir.exists()
        assert expected_dir.is_dir()

    def test_writes_json_file(self, tmp_path):
        """Test writes JSON file with correct filename."""
        output_dir = tmp_path / "output"
        pr_data = {
            "pr_number": 123,
            "title": "Test PR",
            "author": "testuser",
        }

        gh_pr_extract_comments.write_pr_json(output_dir, "owner", "repo", pr_data)

        json_file = output_dir / "owner" / "repo" / "123.json"
        assert json_file.exists()

        # Verify content
        with open(json_file, "r", encoding="utf-8") as f:
            loaded_data = json.load(f)
        assert loaded_data == pr_data

    def test_overwrites_existing_file(self, tmp_path):
        """Test overwrites existing JSON file."""
        output_dir = tmp_path / "output"
        repo_dir = output_dir / "owner" / "repo"
        repo_dir.mkdir(parents=True)

        # Write initial file
        json_file = repo_dir / "123.json"
        json_file.write_text('{"old": "data"}', encoding="utf-8")

        # Write new data
        pr_data = {"pr_number": 123, "title": "New PR"}
        gh_pr_extract_comments.write_pr_json(output_dir, "owner", "repo", pr_data)

        # Verify overwritten
        with open(json_file, "r", encoding="utf-8") as f:
            loaded_data = json.load(f)
        assert loaded_data == pr_data

    def test_raises_on_write_error(self, tmp_path):
        """Test raises exception on write error."""
        # Create a directory where the file should be
        output_dir = tmp_path / "output"
        repo_dir = output_dir / "owner" / "repo"
        repo_dir.mkdir(parents=True)
        (repo_dir / "123.json").mkdir()  # Create directory instead of file

        pr_data = {"pr_number": 123, "title": "Test PR"}

        with pytest.raises(Exception):
            gh_pr_extract_comments.write_pr_json(output_dir, "owner", "repo", pr_data)


class TestParseArguments:
    """Test command-line argument parsing."""

    def test_requires_csv_dir(self):
        """Test requires --csv-dir argument."""
        with mock.patch.object(sys, "argv", ["gh-pr-extract-comments"]):
            with pytest.raises(SystemExit):
                gh_pr_extract_comments.parse_arguments()

    def test_requires_output_dir(self):
        """Test requires --output-dir argument."""
        with mock.patch.object(sys, "argv", ["gh-pr-extract-comments", "--csv-dir", "data/"]):
            with pytest.raises(SystemExit):
                gh_pr_extract_comments.parse_arguments()

    def test_requires_start_date(self):
        """Test requires --start-date argument."""
        with mock.patch.object(
            sys,
            "argv",
            ["gh-pr-extract-comments", "--csv-dir", "data/", "--output-dir", "output/"],
        ):
            with pytest.raises(SystemExit):
                gh_pr_extract_comments.parse_arguments()

    def test_parses_all_required_arguments(self):
        """Test parses all required arguments."""
        with mock.patch.object(
            sys,
            "argv",
            [
                "gh-pr-extract-comments",
                "--csv-dir",
                "data/",
                "--output-dir",
                "output/",
                "--start-date",
                "2024-01-01",
            ],
        ):
            args = gh_pr_extract_comments.parse_arguments()
            assert args.csv_dir == "data/"
            assert args.output_dir == "output/"
            assert args.start_date == "2024-01-01"

    def test_parses_count_argument(self):
        """Test parses --count argument."""
        with mock.patch.object(
            sys,
            "argv",
            [
                "gh-pr-extract-comments",
                "--csv-dir",
                "data/",
                "--output-dir",
                "output/",
                "--start-date",
                "2024-01-01",
                "--count",
                "5",
            ],
        ):
            args = gh_pr_extract_comments.parse_arguments()
            assert args.count == 5

    def test_count_defaults_to_one(self):
        """Test --count defaults to 1."""
        with mock.patch.object(
            sys,
            "argv",
            [
                "gh-pr-extract-comments",
                "--csv-dir",
                "data/",
                "--output-dir",
                "output/",
                "--start-date",
                "2024-01-01",
            ],
        ):
            args = gh_pr_extract_comments.parse_arguments()
            assert args.count == 1

    def test_parses_debug_flag(self):
        """Test parses --debug flag."""
        with mock.patch.object(
            sys,
            "argv",
            [
                "gh-pr-extract-comments",
                "--csv-dir",
                "data/",
                "--output-dir",
                "output/",
                "--start-date",
                "2024-01-01",
                "--debug",
            ],
        ):
            args = gh_pr_extract_comments.parse_arguments()
            assert args.debug is True

    def test_debug_defaults_to_false(self):
        """Test --debug defaults to False."""
        with mock.patch.object(
            sys,
            "argv",
            [
                "gh-pr-extract-comments",
                "--csv-dir",
                "data/",
                "--output-dir",
                "output/",
                "--start-date",
                "2024-01-01",
            ],
        ):
            args = gh_pr_extract_comments.parse_arguments()
            assert args.debug is False


class TestMain:
    """Test main entry point."""

    def test_fails_when_csv_dir_not_found(self, tmp_path):
        """Test returns error when CSV directory doesn't exist."""
        with mock.patch.object(
            sys,
            "argv",
            [
                "gh-pr-extract-comments",
                "--csv-dir",
                str(tmp_path / "nonexistent"),
                "--output-dir",
                str(tmp_path / "output"),
                "--start-date",
                "2024-01-01",
            ],
        ):
            result = gh_pr_extract_comments.main()
            assert result == 1

    def test_fails_on_invalid_start_date(self, tmp_path):
        """Test returns error when start date is invalid."""
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()

        with mock.patch.object(
            sys,
            "argv",
            [
                "gh-pr-extract-comments",
                "--csv-dir",
                str(csv_dir),
                "--output-dir",
                str(tmp_path / "output"),
                "--start-date",
                "invalid-date",
            ],
        ):
            result = gh_pr_extract_comments.main()
            assert result == 1

    def test_fails_when_no_repos_found(self, tmp_path):
        """Test returns error when no repositories with CSV files found."""
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()

        # Create empty state file
        state_file = Path.home() / ".gh-pr-metrics-state.yaml"
        original_exists = state_file.exists()
        original_content = None
        if original_exists:
            original_content = state_file.read_text()

        try:
            state_file.write_text("", encoding="utf-8")

            with mock.patch.object(
                sys,
                "argv",
                [
                    "gh-pr-extract-comments",
                    "--csv-dir",
                    str(csv_dir),
                    "--output-dir",
                    str(tmp_path / "output"),
                    "--start-date",
                    "2024-01-01",
                ],
            ):
                result = gh_pr_extract_comments.main()
                assert result == 1
        finally:
            if original_exists:
                state_file.write_text(original_content)
            else:
                state_file.unlink(missing_ok=True)

    @mock.patch("gh_pr_extract_comments.get_tracked_repos_with_csv")
    @mock.patch("gh_pr_extract_comments.read_prs_from_csv")
    def test_fails_when_no_prs_match_criteria(self, mock_read_prs, mock_get_repos, tmp_path):
        """Test returns error when no PRs match criteria."""
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()

        mock_get_repos.return_value = [
            {"owner": "owner", "repo": "repo", "csv_file": str(tmp_path / "test.csv")}
        ]
        mock_read_prs.return_value = []

        with mock.patch.object(
            sys,
            "argv",
            [
                "gh-pr-extract-comments",
                "--csv-dir",
                str(csv_dir),
                "--output-dir",
                str(tmp_path / "output"),
                "--start-date",
                "2024-01-01",
            ],
        ):
            result = gh_pr_extract_comments.main()
            assert result == 1

    @mock.patch("gh_pr_extract_comments.get_tracked_repos_with_csv")
    @mock.patch("gh_pr_extract_comments.read_prs_from_csv")
    @mock.patch("gh_pr_extract_comments.QuotaManager")
    def test_fails_when_insufficient_quota(
        self, mock_quota_manager, mock_read_prs, mock_get_repos, tmp_path
    ):
        """Test returns error when API quota is insufficient."""
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()

        mock_get_repos.return_value = [
            {"owner": "owner", "repo": "repo", "csv_file": str(tmp_path / "test.csv")}
        ]
        mock_read_prs.return_value = [
            {"pr_number": 123, "created_at": datetime(2024, 1, 15, tzinfo=timezone.utc)}
        ]

        # Mock quota manager to show insufficient quota
        mock_manager = mock.Mock()
        mock_manager.initialize.return_value = {"remaining": 100, "limit": 5000}
        mock_manager.get_current_quota.return_value = (10, 5000, None)  # Only 10 remaining
        mock_quota_manager.return_value = mock_manager

        with mock.patch.object(
            sys,
            "argv",
            [
                "gh-pr-extract-comments",
                "--csv-dir",
                str(csv_dir),
                "--output-dir",
                str(tmp_path / "output"),
                "--start-date",
                "2024-01-01",
            ],
        ):
            result = gh_pr_extract_comments.main()
            assert result == 1

    @mock.patch("gh_pr_extract_comments.get_tracked_repos_with_csv")
    @mock.patch("gh_pr_extract_comments.read_prs_from_csv")
    @mock.patch("gh_pr_extract_comments.fetch_pr_details")
    @mock.patch("gh_pr_extract_comments.QuotaManager")
    @mock.patch("gh_pr_extract_comments.GitHubClient")
    def test_success_with_valid_prs(
        self,
        mock_client_class,
        mock_quota_manager,
        mock_fetch,
        mock_read_prs,
        mock_get_repos,
        tmp_path,
    ):
        """Test successful extraction of PR data."""
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()

        mock_get_repos.return_value = [
            {"owner": "owner", "repo": "repo", "csv_file": str(tmp_path / "test.csv")}
        ]
        mock_read_prs.return_value = [
            {"pr_number": 123, "created_at": datetime(2024, 1, 15, tzinfo=timezone.utc)}
        ]

        # Mock quota manager
        mock_manager = mock.Mock()
        mock_manager.initialize.return_value = {"remaining": 5000, "limit": 5000}
        mock_manager.get_current_quota.return_value = (5000, 5000, None)
        mock_quota_manager.return_value = mock_manager

        # Mock PR details
        mock_fetch.return_value = {
            "pr_number": 123,
            "title": "Test PR",
            "author": "testuser",
            "issue_comments": [],
            "review_comments": [],
            "reviews": [],
        }

        with mock.patch.object(
            sys,
            "argv",
            [
                "gh-pr-extract-comments",
                "--csv-dir",
                str(csv_dir),
                "--output-dir",
                str(tmp_path / "output"),
                "--start-date",
                "2024-01-01",
            ],
        ):
            result = gh_pr_extract_comments.main()
            assert result == 0

        # Verify JSON file was created
        json_file = tmp_path / "output" / "owner" / "repo" / "123.json"
        assert json_file.exists()

    @mock.patch("gh_pr_extract_comments.get_tracked_repos_with_csv")
    @mock.patch("gh_pr_extract_comments.read_prs_from_csv")
    @mock.patch("gh_pr_extract_comments.fetch_pr_details")
    @mock.patch("gh_pr_extract_comments.QuotaManager")
    @mock.patch("gh_pr_extract_comments.GitHubClient")
    def test_partial_failure_returns_error(
        self,
        mock_client_class,
        mock_quota_manager,
        mock_fetch,
        mock_read_prs,
        mock_get_repos,
        tmp_path,
    ):
        """Test returns error when some PRs fail to process."""
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()

        mock_get_repos.return_value = [
            {"owner": "owner", "repo": "repo", "csv_file": str(tmp_path / "test.csv")}
        ]
        mock_read_prs.return_value = [
            {"pr_number": 123, "created_at": datetime(2024, 1, 15, tzinfo=timezone.utc)},
            {"pr_number": 124, "created_at": datetime(2024, 1, 14, tzinfo=timezone.utc)},
        ]

        # Mock quota manager
        mock_manager = mock.Mock()
        mock_manager.initialize.return_value = {"remaining": 5000, "limit": 5000}
        mock_manager.get_current_quota.return_value = (5000, 5000, None)
        mock_quota_manager.return_value = mock_manager

        # First PR succeeds, second fails
        mock_fetch.side_effect = [
            {
                "pr_number": 123,
                "title": "Test PR",
                "author": "testuser",
                "issue_comments": [],
                "review_comments": [],
                "reviews": [],
            },
            None,  # Second PR fails
        ]

        with mock.patch.object(
            sys,
            "argv",
            [
                "gh-pr-extract-comments",
                "--csv-dir",
                str(csv_dir),
                "--output-dir",
                str(tmp_path / "output"),
                "--start-date",
                "2024-01-01",
            ],
        ):
            result = gh_pr_extract_comments.main()
            assert result == 1

    @mock.patch("gh_pr_extract_comments.get_tracked_repos_with_csv")
    @mock.patch("gh_pr_extract_comments.read_prs_from_csv")
    def test_creates_output_directory(self, mock_read_prs, mock_get_repos, tmp_path):
        """Test creates output directory if it doesn't exist."""
        csv_dir = tmp_path / "csv"
        csv_dir.mkdir()
        output_dir = tmp_path / "nonexistent" / "output"

        mock_get_repos.return_value = []
        mock_read_prs.return_value = []

        with mock.patch.object(
            sys,
            "argv",
            [
                "gh-pr-extract-comments",
                "--csv-dir",
                str(csv_dir),
                "--output-dir",
                str(output_dir),
                "--start-date",
                "2024-01-01",
            ],
        ):
            # Will fail due to no repos, but should still create output dir
            gh_pr_extract_comments.main()

        assert output_dir.exists()
        assert output_dir.is_dir()
